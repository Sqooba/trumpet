
To operate Trumpet on a day-to-day basis, tools are provided to help to understand what's going on in Trumpet


## Validate correctness and completeness

A tool is provided which goes back in time as much it can both in the kafka topic and `dfs.*.name.dir` 
and validate that all the transactions in the edit log dir are in Kafka and match:

```
$ /opt/trumpet/server/bin/events-validator.sh --zk.connect <zk_ip:2181> --dfs.edits.dir <root_dir_where_edits_files_are_stored> --numofevents 1000000
```

## Peek Kafka topic

At any time, you can peek the Kafka topic, i.e. retrieve and display in a console the _n_ latest messages:

```
$ /opt/trumpet/server/bin/peek-events.sh --zk.connect <zk_ip:2181> --numofevents 100
```

## Workers status

An utility is also provided to display the running Trumpet workers as well as which one is the leader

```
$ /opt/trumpet/server/bin/list-trumpet-workers.sh --zk.connect <zk_ip:2181>
```


## Use it <a id="Use"></a>

Trumpet comes out as a new building block in the Hadoop ecosystem 
and unleashes brand new capabilities to HDFS. As it relies mostly on Kafka 
for the distribution of the events to the clients, it scales pretty well.

One really promising use-case built on top of Trumpet in near-real time data replication 
from a source HDFS cluster to a destination HDFS cluster.

TODO: other use-cases here

